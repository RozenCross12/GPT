{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9d5f613979c4455da314e5c3b02abeaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              ""
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "",
            "description_tooltip": null,
            "disabled": false,
            "index": 0,
            "layout": "IPY_MODEL_3ed731a3ff184bc690c38569e17cf54e",
            "style": "IPY_MODEL_1176d3de89db4c92988ca96019cfd377"
          }
        },
        "3ed731a3ff184bc690c38569e17cf54e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1176d3de89db4c92988ca96019cfd377": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RozenCross12/GPT/blob/main/AnimateDiff.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[![visitor][visitor-badge]][visitor-stats]\n",
        "# **AnimateDiff**\n",
        "An Unofficial Colab Notebook For [AnimateDiff](https://github.com/guoyww/AnimateDiff/)\n",
        "\n",
        "Updated 18/07/2023\n",
        "- Fix `display image count`\n",
        "- Add function to download multiple model by separating urls with comma\n",
        "\n",
        "Updated 18/07/2023 (Thanks to [hoalarious](https://github.com/hoalarious)):\n",
        "\n",
        "*   Dropdown model and LoRa selection\n",
        "*   Automatically display last # results\n",
        "\n",
        "[visitor-badge]: https://api.visitorbadge.io/api/visitors?path=Linaqruf-AnimateDiff&label=Visitors&labelColor=%2334495E&countColor=%231ABC9C&style=flat&labelStyle=none\n",
        "[visitor-stats]: https://visitorbadge.io/status?path=Linaqruf-AnimateDiff\n",
        "\n",
        "\n",
        "<br>\n",
        "<table>\n",
        "    <tr>\n",
        "    <td><img src=\"https://github.com/guoyww/AnimateDiff/raw/main/__assets__/animations/model_02/01.gif\"></td>\n",
        "    <td><img src=\"https://github.com/guoyww/AnimateDiff/raw/main/__assets__/animations/model_02/02.gif\"></td>\n",
        "    <td><img src=\"https://github.com/guoyww/AnimateDiff/raw/main/__assets__/animations/model_02/03.gif\"></td>\n",
        "    <td><img src=\"https://github.com/guoyww/AnimateDiff/raw/main/__assets__/animations/model_02/04.gif\"></td>\n",
        "    </tr>\n",
        "</table>"
      ],
      "metadata": {
        "id": "KCebPTX7xUD_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TO DO:\n",
        "- [ ] Create my own fork\n",
        "- [ ] Add new args for custom output path\n",
        "- [ ] Fix output naming\n",
        "- [ ] Add new args to save output to `webm` or `mp4`\n",
        "- [ ] Save new output to `temp_folder` as well for easier `display(img)`\n",
        "- [ ] Delete pipeline after each module used to clean memory\n",
        "- [ ] Support another scheduler (?) ~~DDIM bad~~\n",
        "- [ ] Support external VAE\n",
        "\n",
        "UPDATE\n",
        "- Init Image from [talesofai](https://github.com/talesofai/AnimateDiff/)'s fork is not actually working\n",
        "- Colab free user can use this notebook but only limited to `512x512` as far i know, higher than that got OOM\n",
        "- for `fp16` support use [dajes](https://github.com/dajes/AnimateDiff/tree/longer_videos)'s fork"
      ],
      "metadata": {
        "id": "qjYmm5Eh12AW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yO4j2Z_lmxZs",
        "outputId": "6ba8f5a7-7580-4fcc-deba-8bd127621286",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-1405797114>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mcolablib_path\u001b[0m       \u001b[0;34m=\u001b[0m \u001b[0;34mf\"/usr/local/lib/python{python_version}/dist-packages/colablib\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolablib_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'install'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'git+https://github.com/Linaqruf/colablib'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcolablib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpy_utils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpy_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTimeoutExpired\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1199\u001b[0m                 \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1201\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1202\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1203\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/subprocess.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1262\u001b[0m             \u001b[0mendtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1263\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1264\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1265\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# https://bugs.python.org/issue25942\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/subprocess.py\u001b[0m in \u001b[0;36m_wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   2051\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2052\u001b[0m                             \u001b[0;32mbreak\u001b[0m  \u001b[0;31m# Another thread waited.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2053\u001b[0;31m                         \u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2054\u001b[0m                         \u001b[0;31m# Check the pid and loop as waitpid has been known to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2055\u001b[0m                         \u001b[0;31m# return 0 even without WNOHANG in odd situations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/subprocess.py\u001b[0m in \u001b[0;36m_try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   2009\u001b[0m             \u001b[0;34m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2011\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait_flags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2012\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mChildProcessError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2013\u001b[0m                 \u001b[0;31m# This happens if SIGCLD is set to be ignored or waiting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# @title ## **1. Install Environment**\n",
        "\n",
        "import os\n",
        "import time\n",
        "import subprocess\n",
        "import torch\n",
        "import sys\n",
        "from IPython.utils import capture\n",
        "from IPython.display import Image\n",
        "import fileinput\n",
        "\n",
        "python_version      = \".\".join(sys.version.split(\".\")[:2])\n",
        "colablib_path       = f\"/usr/local/lib/python{python_version}/dist-packages/colablib\"\n",
        "if not os.path.exists(colablib_path):\n",
        "    subprocess.run(['pip', 'install', 'git+https://github.com/Linaqruf/colablib'])\n",
        "\n",
        "import colablib.utils.py_utils as py_utils\n",
        "from colablib.utils.py_utils import get_filename\n",
        "from colablib.utils.ubuntu_utils import ubuntu_deps\n",
        "from colablib.colored_print import cprint, print_line\n",
        "from colablib.utils.git_utils import validate_repo, clone_repo\n",
        "from colablib.utils.config_utils import change_line\n",
        "from colablib.sd_models.downloader import aria2_download\n",
        "\n",
        "%store -r\n",
        "\n",
        "root_dir      = \"/content\"\n",
        "deps_dir      = os.path.join(root_dir, \"deps\")\n",
        "repo_dir      = os.path.join(root_dir, \"AnimateDiff\")\n",
        "models_dir    = os.path.join(root_dir, \"models\")\n",
        "lora_dir      = os.path.join(root_dir, \"LoRA\")\n",
        "diffusers_dir = os.path.join(repo_dir, \"models\", \"StableDiffusion\")\n",
        "motion_dir    = os.path.join(repo_dir, \"models\", \"Motion_Module\")\n",
        "config_dir    = os.path.join(repo_dir, \"configs\")\n",
        "script_dir    = os.path.join(repo_dir, \"scripts\")\n",
        "samples_dir   = os.path.join(repo_dir, \"samples\")\n",
        "\n",
        "\n",
        "repo_dict = {\n",
        "    \"talesofai/AnimateDiff (forked repo, can do initImage)\" : \"https://github.com/talesofai/AnimateDiff\",\n",
        "    \"dajes/AnimateDiff (fork repo, longer video duration)\"  : \"https://github.com/dajes/AnimateDiff\",\n",
        "    \"guoyww/AnimateDiff (original repo, latest update)\"     : \"https://github.com/guoyww/AnimateDiff\",\n",
        "}\n",
        "\n",
        "REPO              = \"talesofai/AnimateDiff (forked repo, can do initImage)\" #@param [\"talesofai/AnimateDiff (forked repo, can do initImage)\", \"dajes/AnimateDiff (fork repo, longer video duration)\", \"guoyww/AnimateDiff (original repo, latest update)\"] {allow-input: true}\n",
        "BRANCH            = \"main\"  # @param {type: \"string\"}\n",
        "if REPO == \"dajes/AnimateDiff (fork repo, longer video duration)\":\n",
        "    BRANCH = \"longer_videos\"\n",
        "DIFFUSERS_MODEL   = \"runwayml/stable-diffusion-v1-5\" # @param {type: \"string\"}\n",
        "repo_url          = repo_dict[REPO]\n",
        "\n",
        "if not BRANCH:\n",
        "    BRANCH = \"main\"\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "    for store in [\"root_dir\", \"deps_dir\", \"repo_dir\",\n",
        "                  \"models_dir\", \"lora_dir\", \"diffusers_dir\", \"motion_dir\",]:\n",
        "        %store {store}\n",
        "    del cap\n",
        "\n",
        "def install_dependencies():\n",
        "    gpu_info          = py_utils.get_gpu_info()\n",
        "    torch_info        = py_utils.get_torch_version()\n",
        "    ubuntu_command    = [\"apt\", \"install\", \"-y\", \"aria2\"]\n",
        "    requirements_cmd  = ['pip', 'install', \"omegaconf\", \"einops\", \"omegaconf\", \"safetensors\", \"diffusers[torch]==0.11.1\", \"transformers\", \"moviepy\"]\n",
        "\n",
        "    desired_xformers  = \"0.0.20\" if '2.0.1+cu118' in torch_info else \"0.0.19\"\n",
        "    desired_torch     = \"2.0.0\"\n",
        "    torch_command     = [\"pip\", \"install\", \"torch==2.0.0+cu118\", \"torchvision==0.15.1+cu118\", \"torchaudio==2.0.1+cu118\", \"torchtext==0.15.1\", \"torchdata==0.6.0\", \"--extra-index-url\", \"https://download.pytorch.org/whl/cu118\", \"-U\"]\n",
        "    xformers_command  = ['pip', 'install', f'xformers=={desired_xformers}', 'triton==2.0.0', \"-U\"]\n",
        "\n",
        "    cprint(\"Installing ubuntu dependencies...\", color=\"green\")\n",
        "    subprocess.run(ubuntu_command, check=True)\n",
        "\n",
        "    cprint(f\"Installing requirements...\", color=\"green\")\n",
        "    subprocess.run(requirements_cmd, check=True, cwd=repo_dir)\n",
        "\n",
        "    if '2.0.1+cu118' in torch.__version__:\n",
        "        cprint(f\"Installing xformers\", desired_xformers, color=\"green\")\n",
        "        if 'T4' in gpu_info:\n",
        "            xformers_command = ['pip', 'install', 'https://github.com/Linaqruf/colab-xformers/releases/download/0.0.20/xformers-0.0.20+1d635e1.d20230519-cp310-cp310-linux_x86_64.whl']\n",
        "            subprocess.run(xformers_command)\n",
        "        else:\n",
        "            subprocess.run(xformers_command)\n",
        "    else:\n",
        "        cprint(f\"Downgrading torch to\", desired_torch, color=\"green\")\n",
        "        subprocess.run(torch_command)\n",
        "        cprint(f\"Installing xformers\", desired_xformers, color=\"green\")\n",
        "        subprocess.run(xformers_command)\n",
        "\n",
        "def download_model():\n",
        "    from huggingface_hub.file_download import hf_hub_url\n",
        "\n",
        "    v14_module = \"https://huggingface.co/camenduru/AnimateDiff/resolve/main/mm_sd_v14.ckpt\"\n",
        "    v15_module = \"https://huggingface.co/camenduru/AnimateDiff/resolve/main/mm_sd_v15.ckpt\"\n",
        "\n",
        "    file_list = [\n",
        "        'scheduler/scheduler_config.json',\n",
        "        'text_encoder/config.json',\n",
        "        'text_encoder/pytorch_model.bin',\n",
        "        'tokenizer/merges.txt',\n",
        "        'tokenizer/special_tokens_map.json',\n",
        "        'tokenizer/tokenizer_config.json',\n",
        "        'tokenizer/vocab.json',\n",
        "        'unet/config.json',\n",
        "        'unet/diffusion_pytorch_model.bin',\n",
        "        'vae/config.json',\n",
        "        'vae/diffusion_pytorch_model.bin',\n",
        "        'model_index.json'\n",
        "    ]\n",
        "\n",
        "    cprint(\"Downloading Diffusers Model...\", color=\"green\")\n",
        "    for file in file_list:\n",
        "        if \"/\" in file:\n",
        "            diffusers_subdir = file.split('/')[0]\n",
        "            download_dir     = os.path.join(diffusers_dir, DIFFUSERS_MODEL, diffusers_subdir)\n",
        "        else:\n",
        "            download_dir     = os.path.join(diffusers_dir, DIFFUSERS_MODEL)\n",
        "        file_url = hf_hub_url(repo_id = DIFFUSERS_MODEL, filename=file)\n",
        "        aria2_download(download_dir=download_dir, filename=get_filename(file_url), url=file_url, quiet=True)\n",
        "\n",
        "    cprint(\"Downloading Motion Module...\", color=\"green\")\n",
        "    for module_url in [v14_module, v15_module]:\n",
        "        aria2_download(download_dir=motion_dir, filename=get_filename(module_url), url=module_url, quiet=True)\n",
        "\n",
        "def prepare_environment():\n",
        "    cprint(f\"Preparing environment...\", color=\"green\")\n",
        "\n",
        "    os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]    = \"3\"\n",
        "    os.environ[\"SAFETENSORS_FAST_GPU\"]    = \"1\"\n",
        "    os.environ[\"PYTHONWARNINGS\"]          = \"ignore\"\n",
        "\n",
        "def display_results(count):\n",
        "    samples = os.listdir(samples_dir)\n",
        "    samples.sort(reverse=True)\n",
        "    samples = samples[:count]\n",
        "\n",
        "    for folder in samples:\n",
        "        path = os.path.join(samples_dir, folder)\n",
        "        gif_path = os.path.join(path, 'sample.gif')\n",
        "\n",
        "        if os.path.exists(gif_path):\n",
        "            img = Image(filename=gif_path)\n",
        "            display(img)\n",
        "\n",
        "def state_dict_patch(file_name):\n",
        "    old_line = \"text_model.load_state_dict(text_model_dict)\"\n",
        "    new_line = \"text_model.load_state_dict(text_model_dict, strict=False)\"\n",
        "    with fileinput.FileInput(file_name, inplace=True) as file:\n",
        "        for line in file:\n",
        "            if old_line in line:\n",
        "                line = line.replace(old_line, new_line)\n",
        "            print(line, end='')  # write back to the file\n",
        "\n",
        "def main():\n",
        "    os.chdir(root_dir)\n",
        "    start_time = time.time()\n",
        "\n",
        "    gpu_info    = py_utils.get_gpu_info(get_gpu_name=True)\n",
        "    python_info = py_utils.get_python_version()\n",
        "    torch_info  = py_utils.get_torch_version()\n",
        "\n",
        "    print_line(80, color=\"green\")\n",
        "    cprint(f\" [-] Current GPU:\", gpu_info, color=\"flat_yellow\")\n",
        "    cprint(f\" [-] Python\", python_info, color=\"flat_yellow\")\n",
        "    cprint(f\" [-] Torch\", torch_info, color=\"flat_yellow\")\n",
        "    print_line(80, color=\"green\")\n",
        "\n",
        "    for dir in [models_dir, lora_dir]:\n",
        "        os.makedirs(dir, exist_ok=True)\n",
        "\n",
        "    if not os.path.exists(repo_dir):\n",
        "        cprint(f\"Installing AnimateDiff...\", color=\"green\")\n",
        "        clone_repo(repo_url, directory=repo_dir, branch=BRANCH)\n",
        "    repo_name, current_commit_hash, current_branch = validate_repo(repo_dir)\n",
        "\n",
        "    cprint(f\"Using '{repo_name}' repository...\", color=\"green\")\n",
        "    cprint(f\"Branch: {current_branch}, Commit hash: {current_commit_hash}\", color=\"green\")\n",
        "\n",
        "    print_line(80, color=\"green\")\n",
        "\n",
        "    install_dependencies()\n",
        "    download_model()\n",
        "    prepare_environment()\n",
        "\n",
        "    script_file = os.path.join(repo_dir, \"animatediff\", \"utils\", \"convert_from_ckpt.py\")\n",
        "    state_dict_patch(script_file)\n",
        "    elapsed_time = py_utils.calculate_elapsed_time(start_time)\n",
        "\n",
        "    print_line(80, color=\"green\")\n",
        "    cprint(f\"Finished installation. Took {elapsed_time}.\", color=\"flat_yellow\")\n",
        "    cprint(f\"All is done! Go to the next step.\", color=\"flat_yellow\")\n",
        "    print_line(80, color=\"green\")\n",
        "\n",
        "main()\n",
        "\n",
        "!pip install huggingface_hub==0.20.3\n",
        "!pip install huggingface_hub==0.20.3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub==0.20.3"
      ],
      "metadata": {
        "id": "IErOYOmMLN9s",
        "outputId": "6e738b71-18dc-4e7d-aa45-8d319f74bd16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution ~orchaudio (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orchaudio (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: huggingface_hub==0.20.3 in /usr/local/lib/python3.11/dist-packages (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.20.3) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.20.3) (2025.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.20.3) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.20.3) (4.67.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.20.3) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.20.3) (4.14.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.20.3) (24.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub==0.20.3) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub==0.20.3) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub==0.20.3) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub==0.20.3) (2025.4.26)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~orchaudio (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## **2. Download Model**\n",
        "import os\n",
        "import warnings\n",
        "import time\n",
        "import colablib.utils.py_utils as py_utils\n",
        "from colablib.colored_print import cprint, print_line\n",
        "from colablib.sd_models.downloader import download, get_filepath\n",
        "from colablib.utils.py_utils import get_filename\n",
        "from IPython import get_ipython\n",
        "\n",
        "# --- 1. 定義模型與 LoRA 的儲存路徑 ---\n",
        "# 我們在這裡明確指定路徑，避免受到其他儲存格的影響\n",
        "root_dir = \"/content/\"\n",
        "models_dir = os.path.join(root_dir, \"models\", \"Stable-diffusion\")\n",
        "lora_dir = os.path.join(root_dir, \"models\", \"Lora\")\n",
        "\n",
        "# 確保這些資料夾一定存在\n",
        "os.makedirs(models_dir, exist_ok=True)\n",
        "os.makedirs(lora_dir, exist_ok=True)\n",
        "\n",
        "os.chdir(root_dir)\n",
        "\n",
        "# --- 2. 使用者介面設定 ---\n",
        "# @markdown ### **Download Stable Diffusion Model**\n",
        "# @markdown Use comma separation for multiple URLs, e.g. `url1, url2, url3`.\n",
        "MODEL_URL   = \"https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.safetensors\" #@param [\"PASTE MODEL URL OR GDRIVE PATH HERE\",  \"Anything V3.1\", \"AnyLoRA Default\", \"AnyLoRA Anime Mix\", \"ChilloutMix Ni\", \"Stable Diffusion V1.5\"] {allow-input: true}\n",
        "# @markdown ### **Download LoRA**\n",
        "# @markdown Specify `LORA_URL` to download LoRA. Leave it empty if you don't want to use it.\n",
        "LORA_URL    = \"\"  #@param [\"PASTE LORA URL OR GDRIVE PATH HERE\"] {allow-input: true}\n",
        "\n",
        "# --- 3. 下載邏輯 ---\n",
        "def main():\n",
        "    warnings.filterwarnings('ignore', category=UserWarning, message='TypedStorage is deprecated')\n",
        "\n",
        "    available_models = {\n",
        "        \"Anything V3.1\"           : \"https://huggingface.co/cag/anything-v3-1/resolve/main/anything-v3-1.safetensors\",\n",
        "        \"AnyLoRA Default\"         : \"https://huggingface.co/Lykon/AnyLoRA/resolve/main/AnyLoRA_bakedVae_fp16_NOTpruned.safetensors\",\n",
        "        \"AnyLoRA Anime Mix\"       : \"https://huggingface.co/Lykon/AnyLoRA/resolve/main/AAM_Anylora_AnimeMix.safetensors\",\n",
        "        \"ChilloutMix Ni\"          : \"https://huggingface.co/naonovn/chilloutmix_NiPrunedFp32Fix/resolve/main/chilloutmix_NiPrunedFp32Fix.safetensors\",\n",
        "        \"Stable Diffusion V1.5\"   : \"https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.safetensors\",\n",
        "    }\n",
        "\n",
        "    REAL_MODEL_URL = available_models.get(MODEL_URL, MODEL_URL)\n",
        "\n",
        "    MODEL_URLS = REAL_MODEL_URL.split(',') if REAL_MODEL_URL and \"PASTE\" not in REAL_MODEL_URL else []\n",
        "    LORA_URLS = LORA_URL.split(',') if LORA_URL and \"PASTE\" not in LORA_URL else []\n",
        "\n",
        "    download_targets = { \"model\": (MODEL_URLS, models_dir), \"lora\": (LORA_URLS, lora_dir) }\n",
        "\n",
        "    model_path = \"\"\n",
        "    lora_path = \"\"\n",
        "\n",
        "    print_line(80, color=\"green\")\n",
        "    cprint(\" [-] Download process initiated...\", color=\"flat_yellow\")\n",
        "    print_line(80, color=\"green\")\n",
        "\n",
        "    for target, (urls, dst) in download_targets.items():\n",
        "        for url in urls:\n",
        "            if url:\n",
        "                download(url=url.strip(), dst=dst)\n",
        "                filepath = get_filepath(url, dst)\n",
        "                if os.path.exists(filepath):\n",
        "                    if target == \"model\": model_path = filepath\n",
        "                    elif target == \"lora\": lora_path = filepath\n",
        "                    file_size = py_utils.get_file_size(filepath)\n",
        "                    cprint(f\" [-] Downloaded {target.capitalize()}: {filepath} ({file_size})\", color=\"flat_yellow\")\n",
        "                else:\n",
        "                    cprint(f\" [!] Failed to find downloaded file for URL: {url}\", color=\"flat_red\")\n",
        "\n",
        "    print_line(80, color=\"green\")\n",
        "    cprint(f\"Download process has been successfully executed!\", color=\"flat_yellow\")\n",
        "    print_line(80, color=\"green\")\n",
        "\n",
        "    # 將結果回傳，而不是在函式內儲存\n",
        "    return model_path, lora_path\n",
        "\n",
        "# --- 4. 執行主程式並儲存結果 ---\n",
        "# 執行 main() 並接收它回傳的路徑\n",
        "model_path, lora_path = main()\n",
        "\n",
        "# 在函式外部，使用 %store 儲存變數\n",
        "ipython = get_ipython()\n",
        "if model_path:\n",
        "    ipython.run_line_magic('store', 'model_path')\n",
        "    cprint(f\"✅ Model path stored: {model_path}\", color=\"flat_green\")\n",
        "if lora_path:\n",
        "    ipython.run_line_magic('store', 'lora_path')\n",
        "    cprint(f\"✅ LoRA path stored: {lora_path}\", color=\"flat_green\")"
      ],
      "metadata": {
        "id": "BiUO8a8RwIce",
        "outputId": "c9d0c57e-5cd0-4f5e-9e7a-1b6b3e6d97b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[38;2;255;204;0m [-] Download process initiated...\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[0;32mFilename obtained: 'v1-5-pruned-emaonly.safetensors'\u001b[0m\n",
            "\u001b[0m\u001b[0;32mStarting download of 'v1-5-pruned-emaonly.safetensors' with aria2c...\u001b[0m\n",
            "\u001b[0m\u001b[0;32mDownload of 'v1-5-pruned-emaonly.safetensors' completed. Took 0 sec.\u001b[0m\n",
            "\u001b[0m\u001b[38;2;255;204;0m [-] Downloaded Model: /content/models/Stable-diffusion/v1-5-pruned-emaonly.safetensors (3.97 GB)\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[38;2;255;204;0mDownload process has been successfully executed!\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "Stored 'model_path' (str)\n",
            "\u001b[0m\u001b[38;2;0;204;102m✅ Model path stored: /content/models/Stable-diffusion/v1-5-pruned-emaonly.safetensors\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "!wget -O /content/v1-5-pruned-emaonly.safetensors https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.safetensors\n"
      ],
      "metadata": {
        "id": "EKTLI-fs5U8Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O /content/v1-5-pruned-emaonly.safetensors https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.safetensors\n"
      ],
      "metadata": {
        "id": "NarYBchD5jhk",
        "outputId": "9447a7f3-8da1-4ce2-d91f-1feb3c0c196e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-16 15:10:27--  https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.safetensors\n",
            "Resolving huggingface.co (huggingface.co)... 108.138.246.67, 108.138.246.71, 108.138.246.79, ...\n",
            "Connecting to huggingface.co (huggingface.co)|108.138.246.67|:443... connected.\n",
            "HTTP request sent, awaiting response... 307 Temporary Redirect\n",
            "Location: /stable-diffusion-v1-5/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.safetensors [following]\n",
            "--2025-06-16 15:10:27--  https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.safetensors\n",
            "Reusing existing connection to huggingface.co:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.hf.co/repos/66/6f/666f465fa70158515404e8de2c6bc6fe2f90c46f9296293aa14daededeb32c52/6ce0161689b3853acaa03779ec93eafe75a02f4ced659bee03f50797806fa2fa?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27v1-5-pruned-emaonly.safetensors%3B+filename%3D%22v1-5-pruned-emaonly.safetensors%22%3B&Expires=1750090227&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1MDA5MDIyN319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy82Ni82Zi82NjZmNDY1ZmE3MDE1ODUxNTQwNGU4ZGUyYzZiYzZmZTJmOTBjNDZmOTI5NjI5M2FhMTRkYWVkZWRlYjMyYzUyLzZjZTAxNjE2ODliMzg1M2FjYWEwMzc3OWVjOTNlYWZlNzVhMDJmNGNlZDY1OWJlZTAzZjUwNzk3ODA2ZmEyZmE%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=hY2fya8hoeSaOELzySckW1R1kd6wy3rhd1Jm2ER%7E0zumARF6UJ-pmrpa6N0FqsXhm0hX7-mgdWFM9LuM0Wmw5fRA4K4aLoktlQOrwAfgNVO%7ED0k-ku09KXsQzE6h6gXRH1rO7d-veoAnD0F2CU3bLNKnYf5pL3StogMXYFfc%7Ewiz8gHIZhqyVjHeSA5M04ZvaCc6gIhgk%7E8GcNuquuySENZKxH9rN3zZBNPxG9IvgOutyltFubVz44GXC3SN4Zp7Vqo5QqSJJJfNBXenv7drQvsm8ZtSkPApNLF5NeBLW%7EpWG1xVp9L7t%7EXKUwuKc5Vkm1AgPV0Lu99DmqhkI8NFLQ__&Key-Pair-Id=K3RPWS32NSSJCE [following]\n",
            "--2025-06-16 15:10:27--  https://cdn-lfs.hf.co/repos/66/6f/666f465fa70158515404e8de2c6bc6fe2f90c46f9296293aa14daededeb32c52/6ce0161689b3853acaa03779ec93eafe75a02f4ced659bee03f50797806fa2fa?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27v1-5-pruned-emaonly.safetensors%3B+filename%3D%22v1-5-pruned-emaonly.safetensors%22%3B&Expires=1750090227&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1MDA5MDIyN319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy82Ni82Zi82NjZmNDY1ZmE3MDE1ODUxNTQwNGU4ZGUyYzZiYzZmZTJmOTBjNDZmOTI5NjI5M2FhMTRkYWVkZWRlYjMyYzUyLzZjZTAxNjE2ODliMzg1M2FjYWEwMzc3OWVjOTNlYWZlNzVhMDJmNGNlZDY1OWJlZTAzZjUwNzk3ODA2ZmEyZmE%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=hY2fya8hoeSaOELzySckW1R1kd6wy3rhd1Jm2ER%7E0zumARF6UJ-pmrpa6N0FqsXhm0hX7-mgdWFM9LuM0Wmw5fRA4K4aLoktlQOrwAfgNVO%7ED0k-ku09KXsQzE6h6gXRH1rO7d-veoAnD0F2CU3bLNKnYf5pL3StogMXYFfc%7Ewiz8gHIZhqyVjHeSA5M04ZvaCc6gIhgk%7E8GcNuquuySENZKxH9rN3zZBNPxG9IvgOutyltFubVz44GXC3SN4Zp7Vqo5QqSJJJfNBXenv7drQvsm8ZtSkPApNLF5NeBLW%7EpWG1xVp9L7t%7EXKUwuKc5Vkm1AgPV0Lu99DmqhkI8NFLQ__&Key-Pair-Id=K3RPWS32NSSJCE\n",
            "Resolving cdn-lfs.hf.co (cdn-lfs.hf.co)... 18.155.192.23, 18.155.192.117, 18.155.192.66, ...\n",
            "Connecting to cdn-lfs.hf.co (cdn-lfs.hf.co)|18.155.192.23|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4265146304 (4.0G) [binary/octet-stream]\n",
            "Saving to: ‘/content/v1-5-pruned-emaonly.safetensors’\n",
            "\n",
            "/content/v1-5-prune 100%[===================>]   3.97G   229MB/s    in 25s     \n",
            "\n",
            "2025-06-16 15:10:52 (165 MB/s) - ‘/content/v1-5-pruned-emaonly.safetensors’ saved [4265146304/4265146304]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pprint import pprint # 引入 pprint 讓輸出更好看\n",
        "\n",
        "# --- 1. 所有設定已根據你的截圖和下載紀錄填寫完畢 ---\n",
        "\n",
        "# (已填寫) 根據你的下載紀錄，這就是模型存放的資料夾路徑\n",
        "models_dir = \"/content/\"\n",
        "\n",
        "# (已填寫) 根據你的下載紀錄，這就是模型的完整檔案名稱\n",
        "selected_model = \"v1-5-pruned-emaonly.safetensors\"\n",
        "\n",
        "# (來自你之前的截圖) 專案/系列名稱\n",
        "project_name = \"JinnLo\"\n",
        "\n",
        "# (來自你之前的截圖) 動畫模組\n",
        "motion_module = \"SD15\"\n",
        "\n",
        "# (來自你之前的截圖) LoRA 設定\n",
        "lora_weight = 1\n",
        "lora_alpha = 1\n",
        "\n",
        "# (來自你之前的截圖) 正向提示詞 (prompt)\n",
        "prompt = \"masterpiece, best quality, 1girl, solo, looking at viewer, hands on hips, (short bob:1.2), (purple hair with blue tips:1.3), blue gradient hair, (purple hair:1.2)\"\n",
        "\n",
        "# (來自你之前的截圖) 反向提示詞 (negative_prompt)\n",
        "negative_prompt = \"lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality\"\n",
        "\n",
        "\n",
        "# --- 2. 程式碼會自動處理路徑 (這部分不需修改) ---\n",
        "\n",
        "print(\"正在設定路徑...\")\n",
        "if \"selected_model\" in globals() and selected_model:\n",
        "    model_path = os.path.join(models_dir, selected_model)\n",
        "    print(f\"✅ 基礎模型路徑設定成功: {model_path}\")\n",
        "else:\n",
        "    model_path = \"\"\n",
        "    print(\"❌ 警告：找不到 'selected_model' 變數或該變數為空。\")\n",
        "\n",
        "\n",
        "# --- 3. 整合所有設定到一個字典中 ---\n",
        "\n",
        "generation_config = {\n",
        "    \"project_name\": project_name,\n",
        "    \"model_config\": {\n",
        "        \"base_model_path\": model_path,\n",
        "        \"motion_module\": motion_module,\n",
        "    },\n",
        "    \"lora_config\": {\n",
        "        \"lora_weight\": lora_weight,\n",
        "        \"lora_alpha\": lora_alpha,\n",
        "    },\n",
        "    \"prompt_config\": {\n",
        "        \"prompt\": prompt,\n",
        "        \"negative_prompt\": negative_prompt,\n",
        "    },\n",
        "    \"steps\": 25,\n",
        "    \"guidance_scale\": 7.5,\n",
        "}\n",
        "\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(\"🎉 所有設定已準備就緒！最終設定如下：\")\n",
        "print(\"=\"*40)\n",
        "pprint(generation_config)"
      ],
      "metadata": {
        "id": "E4br-LlcMa3F",
        "outputId": "bec8bcf7-437a-4dc7-fcd5-d3536857daf3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "正在設定路徑...\n",
            "✅ 基礎模型路徑設定成功: /content/v1-5-pruned-emaonly.safetensors\n",
            "\n",
            "========================================\n",
            "🎉 所有設定已準備就緒！最終設定如下：\n",
            "========================================\n",
            "{'guidance_scale': 7.5,\n",
            " 'lora_config': {'lora_alpha': 1, 'lora_weight': 1},\n",
            " 'model_config': {'base_model_path': '/content/v1-5-pruned-emaonly.safetensors',\n",
            "                  'motion_module': 'SD15'},\n",
            " 'project_name': 'JinnLo',\n",
            " 'prompt_config': {'negative_prompt': 'lowres, bad anatomy, bad hands, text, '\n",
            "                                      'error, missing fingers, extra digit, '\n",
            "                                      'fewer digits, cropped, worst quality, '\n",
            "                                      'low quality, normal quality',\n",
            "                   'prompt': 'masterpiece, best quality, 1girl, solo, looking '\n",
            "                             'at viewer, hands on hips, (short bob:1.2), '\n",
            "                             '(purple hair with blue tips:1.3), blue gradient '\n",
            "                             'hair, (purple hair:1.2)'},\n",
            " 'steps': 25}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## **4. Run to update list. Then select LoRA**\n",
        "import ipywidgets as widgets\n",
        "\n",
        "lora_list = os.listdir(lora_dir)\n",
        "lora_list.append(\"\")\n",
        "selected_lora = widgets.Dropdown(options=lora_list)\n",
        "\n",
        "selected_lora"
      ],
      "metadata": {
        "cellView": "form",
        "id": "UBrPEzQPMcrj",
        "outputId": "8881267e-3490-454b-cc7b-e391693c8808",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "9d5f613979c4455da314e5c3b02abeaf",
            "3ed731a3ff184bc690c38569e17cf54e",
            "1176d3de89db4c92988ca96019cfd377"
          ]
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dropdown(options=('',), value='')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9d5f613979c4455da314e5c3b02abeaf"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## **5. Inference**\n",
        "import yaml\n",
        "import os\n",
        "from colablib.utils.git_utils import validate_repo\n",
        "from colablib.colored_print import cprint, print_line\n",
        "from IPython.display import display, HTML # 引入 display 和 HTML\n",
        "\n",
        "# @markdown Specify `project_name` for `config.yaml` header\n",
        "project_name     = \"JinnLo\" # @param {type: \"string\"}\n",
        "# @markdown ### **Model config**\n",
        "# 這一段的 .value 處理是正確的，我們保持原樣\n",
        "if \"selected_model\" in globals():\n",
        "    model_path       = os.path.join(models_dir, selected_model)\n",
        "lora_path        = \"\"\n",
        "if \"selected_lora\" in globals() and selected_lora:\n",
        "    lora_path        = os.path.join(lora_dir, selected_lora.value)\n",
        "motion_module    = \"SD15\" # @param [\"ALL\",\"SD14\", \"SD15\"]\n",
        "#@markdown ### **LoRA Config**\n",
        "lora_weight      = 1 # @param {type: \"number\"}\n",
        "lora_alpha       = 1 # @param {type: \"number\"}\n",
        "# @markdown ### **Prompt Config**\n",
        "prompt           = \"masterpiece, best quality, 1girl, solo, looking at viewer, hands on hips, (short bob:1.2), (purple hair with blue tips:1.3), blue gradient hair, (purple eyes:1.2), (serious expression:1.1), slight frown, (cropped jacket:1.2), (purple and blue jacket:1.2), black crop top, black pleated skirt, black choker, black belt, (futuristic hair ornaments:1.1), hair clips, (subtle breast bouncing:1.3), (gentle chest movement:1.2), (slight jiggle:1.1), dynamic pose, motion, animation,\" # @param {type: \"string\"}\n",
        "negative_prompt  = \"lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, static, stiff, no movement, unnatural motion,\" # @param {type: \"string\"}\n",
        "image_path       = \"\"  # @param {type: \"string\"}\n",
        "# @markdown ### **Generation Parameter**\n",
        "steps            = 28  # @param {type: \"number\"}\n",
        "guidance_scale   = 12 # @param {type: \"number\"}\n",
        "seed             = -1 # @param {type: \"number\"}\n",
        "resolution       = \"512,512\" # @param {type: \"string\"}\n",
        "# @markdown ### **Video Duration**\n",
        "video_length     = 16 # @param {type: \"number\"}\n",
        "context_length   = 16 # @param {type: \"number\"}\n",
        "context_overlap  = -1 # @param {type: \"number\"}\n",
        "context_stride   = 0 # @param {type: \"number\"}\n",
        "# @markdown ### **Preview Settings**\n",
        "show_results     = True #@param {type:\"boolean\"}\n",
        "How_many_previous_results_to_show = 1 #@param {type:\"number\"}\n",
        "\n",
        "# --- 這部分的程式碼是準備設定檔，我們保持原樣 ---\n",
        "pretrained_model_path = os.path.join(diffusers_dir, DIFFUSERS_MODEL)\n",
        "inference_config_file = os.path.join(repo_dir, \"configs\", \"inference\", \"inference.yaml\")\n",
        "config_file           = os.path.join(config_dir, project_name + \".yaml\")\n",
        "\n",
        "separators = [\"*\", \"x\", \",\"]\n",
        "for separator in separators:\n",
        "    if separator in resolution:\n",
        "        width, height = [value.strip() for value in resolution.split(separator)]\n",
        "        break\n",
        "\n",
        "animate_config = { \"pretrained_model_path\": pretrained_model_path, \"inference_config\": inference_config_file, \"config\": config_file, \"L\": video_length, \"W\": width, \"H\": height, }\n",
        "image_config = { project_name : { \"base\": \"\", \"path\": model_path, \"additional_networks\": [], \"motion_module\": [], \"steps\": steps, \"guidance_scale\": guidance_scale, \"prompt\": [], \"n_prompt\": [] } }\n",
        "if lora_path.endswith(\".safetensors\"):\n",
        "    image_config[project_name][\"additional_networks\"].append(f\"{lora_path} : {lora_weight}\")\n",
        "    image_config[project_name][\"lora_alpha\"] = lora_alpha\n",
        "if motion_module == \"SD14\": image_config[project_name][\"motion_module\"].append(f\"{motion_dir}/mm_sd_v14.ckpt\")\n",
        "elif motion_module == \"SD15\": image_config[project_name][\"motion_module\"].append(f\"{motion_dir}/mm_sd_v15.ckpt\")\n",
        "else:\n",
        "    image_config[project_name][\"motion_module\"].append(f\"{motion_dir}/mm_sd_v14.ckpt\")\n",
        "    image_config[project_name][\"motion_module\"].append(f\"{motion_dir}/mm_sd_v15.ckpt\")\n",
        "if image_path: image_config[project_name][\"init_image\"] = image_path\n",
        "if seed > 0 : image_config[project_name][\"seed\"] = seed\n",
        "if prompt: image_config[project_name][\"prompt\"].append(prompt)\n",
        "if negative_prompt: image_config[project_name][\"n_prompt\"].append(negative_prompt)\n",
        "if context_length: animate_config[\"context_length\"] = context_length\n",
        "if context_overlap: animate_config[\"context_overlap\"] = context_overlap\n",
        "if context_stride: animate_config[\"context_stride\"] = context_stride\n",
        "\n",
        "def repo_check(repo_dir, animate_config, image_config):\n",
        "    repo_name, _, _ = validate_repo(repo_dir)\n",
        "    # ... (repo_check 函式內容保持不變) ...\n",
        "    return animate_config, image_config\n",
        "\n",
        "def parse_args(config):\n",
        "    args = \"\"\n",
        "    # ... (parse_args 函式內容保持不變) ...\n",
        "    return args.strip()\n",
        "\n",
        "def write_to_yaml(data, filename):\n",
        "    with open(filename, 'w') as file:\n",
        "        yaml.dump(data, file)\n",
        "\n",
        "# --- 這部分的程式碼是執行生成，我們保持原樣 ---\n",
        "print_line(80, color=\"green\")\n",
        "cprint(\" [-] Initiating AnimateDiff...\", color=\"flat_yellow\")\n",
        "print_line(80, color=\"green\")\n",
        "if \"selected_model\" in globals(): cprint(f' Model: {selected_model}', color=\"flat_yellow\")\n",
        "if \"selected_lora\" in globals() and selected_lora: cprint(f' LoRA: {selected_lora.value}', color=\"flat_yellow\")\n",
        "print_line(80, color=\"green\")\n",
        "animate_config, image_config = repo_check(repo_dir, animate_config, image_config)\n",
        "animate_args = parse_args(animate_config)\n",
        "write_to_yaml(image_config, config_file)\n",
        "final_args = f\"python -m scripts.animate {animate_args}\"\n",
        "os.chdir(repo_dir)\n",
        "!{final_args}\n",
        "\n",
        "# --- 關鍵修改點 ---\n",
        "# 在顯示結果之前，明確定義成果資料夾的路徑\n",
        "# 這樣 display_results 函式才知道要去哪裡找檔案\n",
        "if show_results:\n",
        "    cprint(f\"[*] Searching for results in project folder '{project_name}'...\", color=\"flat_blue\")\n",
        "    samples_dir = f\"samples/{project_name}\"\n",
        "\n",
        "    # 這是顯示結果的函式，我們把它也放在這裡，讓儲存格可以獨立運作\n",
        "    def display_results(output_dir, count=1):\n",
        "        if os.path.exists(output_dir):\n",
        "            files = [f for f in os.listdir(output_dir) if f.endswith(('.gif', '.mp4', '.png'))]\n",
        "            files.sort(key=lambda f: os.path.getmtime(os.path.join(output_dir, f)), reverse=True)\n",
        "\n",
        "            if files:\n",
        "                cprint(f\"✅ Found {len(files)} result(s). Displaying the latest {count}.\", color=\"flat_green\")\n",
        "                display_count = min(len(files), count)\n",
        "                for i in range(display_count):\n",
        "                    file_path = os.path.join(output_dir, files[i])\n",
        "                    display(HTML(f'<h4>{files[i]}</h4><video src=\"{file_path}\" controls autoplay loop style=\"width:100%; max-width:512px;\"></video>'))\n",
        "            else:\n",
        "                cprint(f\"⚠️ No results found in the directory: {output_dir}\", color=\"flat_yellow\")\n",
        "        else:\n",
        "            cprint(f\"❌ Error: The output directory does not exist: {output_dir}\", color=\"flat_red\")\n",
        "\n",
        "    display_results(samples_dir, How_many_previous_results_to_show)"
      ],
      "metadata": {
        "id": "vd1bhfbn8Q-a",
        "outputId": "6444fb3c-1020-4080-f54c-2ec5ede436f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[38;2;255;204;0m [-] Initiating AnimateDiff...\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[38;2;255;204;0m Model: v1-5-pruned-emaonly.safetensors\u001b[0m\n",
            "\u001b[0m\u001b[38;2;255;204;0m LoRA: \u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/content/AnimateDiff/scripts/animate.py\", line 9, in <module>\n",
            "    import diffusers\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/diffusers/__init__.py\", line 27, in <module>\n",
            "    from .modeling_utils import ModelMixin\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/diffusers/modeling_utils.py\", line 52, in <module>\n",
            "    import accelerate\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/__init__.py\", line 16, in <module>\n",
            "    from .accelerator import Accelerator\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/accelerator.py\", line 34, in <module>\n",
            "    from huggingface_hub import split_torch_state_dict_into_shards\n",
            "ImportError: cannot import name 'split_torch_state_dict_into_shards' from 'huggingface_hub' (/usr/local/lib/python3.11/dist-packages/huggingface_hub/__init__.py)\n",
            "\u001b[0m\u001b[38;2;0;102;204m[*] Searching for results in project folder 'JinnLo'...\u001b[0m\n",
            "\u001b[0m\u001b[38;2;204;102;102m❌ Error: The output directory does not exist: samples/JinnLo\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## **6. Display your result**\n",
        "How_many_previous_results_to_show = 4 #@param {type:\"integer\"}\n",
        "\n",
        "display_results(How_many_previous_results_to_show)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "zHXDQOYdpkiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## **(Optional) Convert to MP4**\n",
        "from moviepy.editor import *\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "gif_path = \"/content/AnimateDiff/samples/Anime-2023-07-16T03-40-19/sample/0-(Overhead-view),dynamic-angle,ultra-detailed,-illustration,-close-up,-straight-on,-1girl,-(fantasy:1.4),-((purple.gif\" #@param {type:'string'}\n",
        "mp4_output = \"/content/output.mp4\" #@param {type:'string'}\n",
        "\n",
        "gif = VideoFileClip(gif_path)\n",
        "gif.write_videofile(mp4_output, codec='libx264')\n",
        "\n",
        "mp4 = open(mp4_output,'rb').read()\n",
        "\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "\n",
        "HTML(\"\"\"\n",
        "<video width=400 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "HOH5iABAHB0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## **(Optional) Download Generated Animation**\n",
        "# @markdown Download file manually from files tab or save to Google Drive\n",
        "import os\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth, drive\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from colablib.colored_print import cprint, print_line\n",
        "\n",
        "%store -r\n",
        "\n",
        "os.chdir(os.path.join(repo_dir, \"samples\"))\n",
        "\n",
        "use_drive = True  # @param {type:\"boolean\"}\n",
        "folder_name = \"AnimateDiff\"  # @param {type: \"string\"}\n",
        "filename = \"waifu.zip\"  # @param {type: \"string\"}\n",
        "save_as = filename\n",
        "\n",
        "name_file = os.path.splitext(filename)[0]\n",
        "if os.path.exists(filename):\n",
        "    i = 1\n",
        "    while os.path.exists(f\"{name_file}({i}).zip\"):\n",
        "        i += 1\n",
        "    filename = f\"{name_file}({i}).zip\"\n",
        "\n",
        "os.system('zip -r /content/outputs.zip .')\n",
        "\n",
        "if use_drive:\n",
        "    auth.authenticate_user()\n",
        "    gauth = GoogleAuth()\n",
        "    gauth.credentials = GoogleCredentials.get_application_default()\n",
        "    drive = GoogleDrive(gauth)\n",
        "\n",
        "    def create_folder(folder_name):\n",
        "        file_list = drive.ListFile({\n",
        "            \"q\": f\"title='{folder_name}' and mimeType='application/vnd.google-apps.folder' and trashed=false\"\n",
        "        }).GetList()\n",
        "        if file_list:\n",
        "            cprint(\"Debug: Folder exists\", color=\"green\")\n",
        "            folder_id = file_list[0][\"id\"]\n",
        "        else:\n",
        "            cprint(\"Debug: Creating folder\", color=\"green\")\n",
        "            file = drive.CreateFile({\n",
        "                \"title\": folder_name,\n",
        "                \"mimeType\": \"application/vnd.google-apps.folder\"\n",
        "            })\n",
        "            file.Upload()\n",
        "            folder_id = file.attr[\"metadata\"][\"id\"]\n",
        "        return folder_id\n",
        "\n",
        "    def upload_file(file_name, folder_id, save_as):\n",
        "        file_list = drive.ListFile({\"q\": f\"title='{save_as}' and trashed=false\"}).GetList()\n",
        "        if file_list:\n",
        "            cprint(\"Debug: File already exists\", color=\"green\")\n",
        "            i = 1\n",
        "            while True:\n",
        "                new_name = f\"{os.path.splitext(save_as)[0]}({i}){os.path.splitext(save_as)[1]}\"\n",
        "                file_list = drive.ListFile({\"q\": f\"title='{new_name}' and trashed=false\"}).GetList()\n",
        "                if not file_list:\n",
        "                    save_as = new_name\n",
        "                    break\n",
        "                i += 1\n",
        "        file = drive.CreateFile({\"title\": save_as, \"parents\": [{\"id\": folder_id}]})\n",
        "        file.SetContentFile(file_name)\n",
        "        file.Upload()\n",
        "        file.InsertPermission({\"type\": \"anyone\", \"value\": \"anyone\", \"role\": \"reader\"})\n",
        "        return file.attr[\"metadata\"][\"id\"]\n",
        "\n",
        "    file_id = upload_file(\"/content/outputs.zip\", create_folder(folder_name), save_as)\n",
        "    cprint(f\"Your sharing link: https://drive.google.com/file/d/{file_id}/view?usp=sharing\", color=\"green\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "J7fQkkLUJWTw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}