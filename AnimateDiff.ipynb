{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9d5f613979c4455da314e5c3b02abeaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              ""
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "",
            "description_tooltip": null,
            "disabled": false,
            "index": 0,
            "layout": "IPY_MODEL_3ed731a3ff184bc690c38569e17cf54e",
            "style": "IPY_MODEL_1176d3de89db4c92988ca96019cfd377"
          }
        },
        "3ed731a3ff184bc690c38569e17cf54e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1176d3de89db4c92988ca96019cfd377": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RozenCross12/GPT/blob/main/AnimateDiff.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[![visitor][visitor-badge]][visitor-stats]\n",
        "# **AnimateDiff**\n",
        "An Unofficial Colab Notebook For [AnimateDiff](https://github.com/guoyww/AnimateDiff/)\n",
        "\n",
        "Updated 18/07/2023\n",
        "- Fix `display image count`\n",
        "- Add function to download multiple model by separating urls with comma\n",
        "\n",
        "Updated 18/07/2023 (Thanks to [hoalarious](https://github.com/hoalarious)):\n",
        "\n",
        "*   Dropdown model and LoRa selection\n",
        "*   Automatically display last # results\n",
        "\n",
        "[visitor-badge]: https://api.visitorbadge.io/api/visitors?path=Linaqruf-AnimateDiff&label=Visitors&labelColor=%2334495E&countColor=%231ABC9C&style=flat&labelStyle=none\n",
        "[visitor-stats]: https://visitorbadge.io/status?path=Linaqruf-AnimateDiff\n",
        "\n",
        "\n",
        "<br>\n",
        "<table>\n",
        "    <tr>\n",
        "    <td><img src=\"https://github.com/guoyww/AnimateDiff/raw/main/__assets__/animations/model_02/01.gif\"></td>\n",
        "    <td><img src=\"https://github.com/guoyww/AnimateDiff/raw/main/__assets__/animations/model_02/02.gif\"></td>\n",
        "    <td><img src=\"https://github.com/guoyww/AnimateDiff/raw/main/__assets__/animations/model_02/03.gif\"></td>\n",
        "    <td><img src=\"https://github.com/guoyww/AnimateDiff/raw/main/__assets__/animations/model_02/04.gif\"></td>\n",
        "    </tr>\n",
        "</table>"
      ],
      "metadata": {
        "id": "KCebPTX7xUD_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TO DO:\n",
        "- [ ] Create my own fork\n",
        "- [ ] Add new args for custom output path\n",
        "- [ ] Fix output naming\n",
        "- [ ] Add new args to save output to `webm` or `mp4`\n",
        "- [ ] Save new output to `temp_folder` as well for easier `display(img)`\n",
        "- [ ] Delete pipeline after each module used to clean memory\n",
        "- [ ] Support another scheduler (?) ~~DDIM bad~~\n",
        "- [ ] Support external VAE\n",
        "\n",
        "UPDATE\n",
        "- Init Image from [talesofai](https://github.com/talesofai/AnimateDiff/)'s fork is not actually working\n",
        "- Colab free user can use this notebook but only limited to `512x512` as far i know, higher than that got OOM\n",
        "- for `fp16` support use [dajes](https://github.com/dajes/AnimateDiff/tree/longer_videos)'s fork"
      ],
      "metadata": {
        "id": "qjYmm5Eh12AW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yO4j2Z_lmxZs",
        "outputId": "6ba8f5a7-7580-4fcc-deba-8bd127621286",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-1405797114>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mcolablib_path\u001b[0m       \u001b[0;34m=\u001b[0m \u001b[0;34mf\"/usr/local/lib/python{python_version}/dist-packages/colablib\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolablib_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'install'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'git+https://github.com/Linaqruf/colablib'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcolablib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpy_utils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpy_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTimeoutExpired\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1199\u001b[0m                 \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1201\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1202\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1203\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/subprocess.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1262\u001b[0m             \u001b[0mendtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1263\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1264\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1265\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# https://bugs.python.org/issue25942\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/subprocess.py\u001b[0m in \u001b[0;36m_wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   2051\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2052\u001b[0m                             \u001b[0;32mbreak\u001b[0m  \u001b[0;31m# Another thread waited.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2053\u001b[0;31m                         \u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2054\u001b[0m                         \u001b[0;31m# Check the pid and loop as waitpid has been known to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2055\u001b[0m                         \u001b[0;31m# return 0 even without WNOHANG in odd situations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/subprocess.py\u001b[0m in \u001b[0;36m_try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   2009\u001b[0m             \u001b[0;34m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2011\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait_flags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2012\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mChildProcessError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2013\u001b[0m                 \u001b[0;31m# This happens if SIGCLD is set to be ignored or waiting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# @title ## **1. Install Environment**\n",
        "\n",
        "import os\n",
        "import time\n",
        "import subprocess\n",
        "import torch\n",
        "import sys\n",
        "from IPython.utils import capture\n",
        "from IPython.display import Image\n",
        "import fileinput\n",
        "\n",
        "python_version      = \".\".join(sys.version.split(\".\")[:2])\n",
        "colablib_path       = f\"/usr/local/lib/python{python_version}/dist-packages/colablib\"\n",
        "if not os.path.exists(colablib_path):\n",
        "    subprocess.run(['pip', 'install', 'git+https://github.com/Linaqruf/colablib'])\n",
        "\n",
        "import colablib.utils.py_utils as py_utils\n",
        "from colablib.utils.py_utils import get_filename\n",
        "from colablib.utils.ubuntu_utils import ubuntu_deps\n",
        "from colablib.colored_print import cprint, print_line\n",
        "from colablib.utils.git_utils import validate_repo, clone_repo\n",
        "from colablib.utils.config_utils import change_line\n",
        "from colablib.sd_models.downloader import aria2_download\n",
        "\n",
        "%store -r\n",
        "\n",
        "root_dir      = \"/content\"\n",
        "deps_dir      = os.path.join(root_dir, \"deps\")\n",
        "repo_dir      = os.path.join(root_dir, \"AnimateDiff\")\n",
        "models_dir    = os.path.join(root_dir, \"models\")\n",
        "lora_dir      = os.path.join(root_dir, \"LoRA\")\n",
        "diffusers_dir = os.path.join(repo_dir, \"models\", \"StableDiffusion\")\n",
        "motion_dir    = os.path.join(repo_dir, \"models\", \"Motion_Module\")\n",
        "config_dir    = os.path.join(repo_dir, \"configs\")\n",
        "script_dir    = os.path.join(repo_dir, \"scripts\")\n",
        "samples_dir   = os.path.join(repo_dir, \"samples\")\n",
        "\n",
        "\n",
        "repo_dict = {\n",
        "    \"talesofai/AnimateDiff (forked repo, can do initImage)\" : \"https://github.com/talesofai/AnimateDiff\",\n",
        "    \"dajes/AnimateDiff (fork repo, longer video duration)\"  : \"https://github.com/dajes/AnimateDiff\",\n",
        "    \"guoyww/AnimateDiff (original repo, latest update)\"     : \"https://github.com/guoyww/AnimateDiff\",\n",
        "}\n",
        "\n",
        "REPO              = \"talesofai/AnimateDiff (forked repo, can do initImage)\" #@param [\"talesofai/AnimateDiff (forked repo, can do initImage)\", \"dajes/AnimateDiff (fork repo, longer video duration)\", \"guoyww/AnimateDiff (original repo, latest update)\"] {allow-input: true}\n",
        "BRANCH            = \"main\"  # @param {type: \"string\"}\n",
        "if REPO == \"dajes/AnimateDiff (fork repo, longer video duration)\":\n",
        "    BRANCH = \"longer_videos\"\n",
        "DIFFUSERS_MODEL   = \"runwayml/stable-diffusion-v1-5\" # @param {type: \"string\"}\n",
        "repo_url          = repo_dict[REPO]\n",
        "\n",
        "if not BRANCH:\n",
        "    BRANCH = \"main\"\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "    for store in [\"root_dir\", \"deps_dir\", \"repo_dir\",\n",
        "                  \"models_dir\", \"lora_dir\", \"diffusers_dir\", \"motion_dir\",]:\n",
        "        %store {store}\n",
        "    del cap\n",
        "\n",
        "def install_dependencies():\n",
        "    gpu_info          = py_utils.get_gpu_info()\n",
        "    torch_info        = py_utils.get_torch_version()\n",
        "    ubuntu_command    = [\"apt\", \"install\", \"-y\", \"aria2\"]\n",
        "    requirements_cmd  = ['pip', 'install', \"omegaconf\", \"einops\", \"omegaconf\", \"safetensors\", \"diffusers[torch]==0.11.1\", \"transformers\", \"moviepy\"]\n",
        "\n",
        "    desired_xformers  = \"0.0.20\" if '2.0.1+cu118' in torch_info else \"0.0.19\"\n",
        "    desired_torch     = \"2.0.0\"\n",
        "    torch_command     = [\"pip\", \"install\", \"torch==2.0.0+cu118\", \"torchvision==0.15.1+cu118\", \"torchaudio==2.0.1+cu118\", \"torchtext==0.15.1\", \"torchdata==0.6.0\", \"--extra-index-url\", \"https://download.pytorch.org/whl/cu118\", \"-U\"]\n",
        "    xformers_command  = ['pip', 'install', f'xformers=={desired_xformers}', 'triton==2.0.0', \"-U\"]\n",
        "\n",
        "    cprint(\"Installing ubuntu dependencies...\", color=\"green\")\n",
        "    subprocess.run(ubuntu_command, check=True)\n",
        "\n",
        "    cprint(f\"Installing requirements...\", color=\"green\")\n",
        "    subprocess.run(requirements_cmd, check=True, cwd=repo_dir)\n",
        "\n",
        "    if '2.0.1+cu118' in torch.__version__:\n",
        "        cprint(f\"Installing xformers\", desired_xformers, color=\"green\")\n",
        "        if 'T4' in gpu_info:\n",
        "            xformers_command = ['pip', 'install', 'https://github.com/Linaqruf/colab-xformers/releases/download/0.0.20/xformers-0.0.20+1d635e1.d20230519-cp310-cp310-linux_x86_64.whl']\n",
        "            subprocess.run(xformers_command)\n",
        "        else:\n",
        "            subprocess.run(xformers_command)\n",
        "    else:\n",
        "        cprint(f\"Downgrading torch to\", desired_torch, color=\"green\")\n",
        "        subprocess.run(torch_command)\n",
        "        cprint(f\"Installing xformers\", desired_xformers, color=\"green\")\n",
        "        subprocess.run(xformers_command)\n",
        "\n",
        "def download_model():\n",
        "    from huggingface_hub.file_download import hf_hub_url\n",
        "\n",
        "    v14_module = \"https://huggingface.co/camenduru/AnimateDiff/resolve/main/mm_sd_v14.ckpt\"\n",
        "    v15_module = \"https://huggingface.co/camenduru/AnimateDiff/resolve/main/mm_sd_v15.ckpt\"\n",
        "\n",
        "    file_list = [\n",
        "        'scheduler/scheduler_config.json',\n",
        "        'text_encoder/config.json',\n",
        "        'text_encoder/pytorch_model.bin',\n",
        "        'tokenizer/merges.txt',\n",
        "        'tokenizer/special_tokens_map.json',\n",
        "        'tokenizer/tokenizer_config.json',\n",
        "        'tokenizer/vocab.json',\n",
        "        'unet/config.json',\n",
        "        'unet/diffusion_pytorch_model.bin',\n",
        "        'vae/config.json',\n",
        "        'vae/diffusion_pytorch_model.bin',\n",
        "        'model_index.json'\n",
        "    ]\n",
        "\n",
        "    cprint(\"Downloading Diffusers Model...\", color=\"green\")\n",
        "    for file in file_list:\n",
        "        if \"/\" in file:\n",
        "            diffusers_subdir = file.split('/')[0]\n",
        "            download_dir     = os.path.join(diffusers_dir, DIFFUSERS_MODEL, diffusers_subdir)\n",
        "        else:\n",
        "            download_dir     = os.path.join(diffusers_dir, DIFFUSERS_MODEL)\n",
        "        file_url = hf_hub_url(repo_id = DIFFUSERS_MODEL, filename=file)\n",
        "        aria2_download(download_dir=download_dir, filename=get_filename(file_url), url=file_url, quiet=True)\n",
        "\n",
        "    cprint(\"Downloading Motion Module...\", color=\"green\")\n",
        "    for module_url in [v14_module, v15_module]:\n",
        "        aria2_download(download_dir=motion_dir, filename=get_filename(module_url), url=module_url, quiet=True)\n",
        "\n",
        "def prepare_environment():\n",
        "    cprint(f\"Preparing environment...\", color=\"green\")\n",
        "\n",
        "    os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]    = \"3\"\n",
        "    os.environ[\"SAFETENSORS_FAST_GPU\"]    = \"1\"\n",
        "    os.environ[\"PYTHONWARNINGS\"]          = \"ignore\"\n",
        "\n",
        "def display_results(count):\n",
        "    samples = os.listdir(samples_dir)\n",
        "    samples.sort(reverse=True)\n",
        "    samples = samples[:count]\n",
        "\n",
        "    for folder in samples:\n",
        "        path = os.path.join(samples_dir, folder)\n",
        "        gif_path = os.path.join(path, 'sample.gif')\n",
        "\n",
        "        if os.path.exists(gif_path):\n",
        "            img = Image(filename=gif_path)\n",
        "            display(img)\n",
        "\n",
        "def state_dict_patch(file_name):\n",
        "    old_line = \"text_model.load_state_dict(text_model_dict)\"\n",
        "    new_line = \"text_model.load_state_dict(text_model_dict, strict=False)\"\n",
        "    with fileinput.FileInput(file_name, inplace=True) as file:\n",
        "        for line in file:\n",
        "            if old_line in line:\n",
        "                line = line.replace(old_line, new_line)\n",
        "            print(line, end='')  # write back to the file\n",
        "\n",
        "def main():\n",
        "    os.chdir(root_dir)\n",
        "    start_time = time.time()\n",
        "\n",
        "    gpu_info    = py_utils.get_gpu_info(get_gpu_name=True)\n",
        "    python_info = py_utils.get_python_version()\n",
        "    torch_info  = py_utils.get_torch_version()\n",
        "\n",
        "    print_line(80, color=\"green\")\n",
        "    cprint(f\" [-] Current GPU:\", gpu_info, color=\"flat_yellow\")\n",
        "    cprint(f\" [-] Python\", python_info, color=\"flat_yellow\")\n",
        "    cprint(f\" [-] Torch\", torch_info, color=\"flat_yellow\")\n",
        "    print_line(80, color=\"green\")\n",
        "\n",
        "    for dir in [models_dir, lora_dir]:\n",
        "        os.makedirs(dir, exist_ok=True)\n",
        "\n",
        "    if not os.path.exists(repo_dir):\n",
        "        cprint(f\"Installing AnimateDiff...\", color=\"green\")\n",
        "        clone_repo(repo_url, directory=repo_dir, branch=BRANCH)\n",
        "    repo_name, current_commit_hash, current_branch = validate_repo(repo_dir)\n",
        "\n",
        "    cprint(f\"Using '{repo_name}' repository...\", color=\"green\")\n",
        "    cprint(f\"Branch: {current_branch}, Commit hash: {current_commit_hash}\", color=\"green\")\n",
        "\n",
        "    print_line(80, color=\"green\")\n",
        "\n",
        "    install_dependencies()\n",
        "    download_model()\n",
        "    prepare_environment()\n",
        "\n",
        "    script_file = os.path.join(repo_dir, \"animatediff\", \"utils\", \"convert_from_ckpt.py\")\n",
        "    state_dict_patch(script_file)\n",
        "    elapsed_time = py_utils.calculate_elapsed_time(start_time)\n",
        "\n",
        "    print_line(80, color=\"green\")\n",
        "    cprint(f\"Finished installation. Took {elapsed_time}.\", color=\"flat_yellow\")\n",
        "    cprint(f\"All is done! Go to the next step.\", color=\"flat_yellow\")\n",
        "    print_line(80, color=\"green\")\n",
        "\n",
        "main()\n",
        "\n",
        "!pip install huggingface_hub==0.20.3\n",
        "!pip install huggingface_hub==0.20.3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub==0.20.3"
      ],
      "metadata": {
        "id": "IErOYOmMLN9s",
        "outputId": "6e738b71-18dc-4e7d-aa45-8d319f74bd16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution ~orchaudio (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orchaudio (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: huggingface_hub==0.20.3 in /usr/local/lib/python3.11/dist-packages (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.20.3) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.20.3) (2025.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.20.3) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.20.3) (4.67.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.20.3) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.20.3) (4.14.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.20.3) (24.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub==0.20.3) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub==0.20.3) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub==0.20.3) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub==0.20.3) (2025.4.26)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~orchaudio (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## **2. Download Model**\n",
        "import os\n",
        "import warnings\n",
        "import time\n",
        "import colablib.utils.py_utils as py_utils\n",
        "from colablib.colored_print import cprint, print_line\n",
        "from colablib.sd_models.downloader import download, get_filepath\n",
        "from colablib.utils.py_utils import get_filename\n",
        "from IPython import get_ipython\n",
        "\n",
        "# --- 1. å®šç¾©æ¨¡å‹èˆ‡ LoRA çš„å„²å­˜è·¯å¾‘ ---\n",
        "# æˆ‘å€‘åœ¨é€™è£¡æ˜ç¢ºæŒ‡å®šè·¯å¾‘ï¼Œé¿å…å—åˆ°å…¶ä»–å„²å­˜æ ¼çš„å½±éŸ¿\n",
        "root_dir = \"/content/\"\n",
        "models_dir = os.path.join(root_dir, \"models\", \"Stable-diffusion\")\n",
        "lora_dir = os.path.join(root_dir, \"models\", \"Lora\")\n",
        "\n",
        "# ç¢ºä¿é€™äº›è³‡æ–™å¤¾ä¸€å®šå­˜åœ¨\n",
        "os.makedirs(models_dir, exist_ok=True)\n",
        "os.makedirs(lora_dir, exist_ok=True)\n",
        "\n",
        "os.chdir(root_dir)\n",
        "\n",
        "# --- 2. ä½¿ç”¨è€…ä»‹é¢è¨­å®š ---\n",
        "# @markdown ### **Download Stable Diffusion Model**\n",
        "# @markdown Use comma separation for multiple URLs, e.g. `url1, url2, url3`.\n",
        "MODEL_URL   = \"https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.safetensors\" #@param [\"PASTE MODEL URL OR GDRIVE PATH HERE\",  \"Anything V3.1\", \"AnyLoRA Default\", \"AnyLoRA Anime Mix\", \"ChilloutMix Ni\", \"Stable Diffusion V1.5\"] {allow-input: true}\n",
        "# @markdown ### **Download LoRA**\n",
        "# @markdown Specify `LORA_URL` to download LoRA. Leave it empty if you don't want to use it.\n",
        "LORA_URL    = \"\"  #@param [\"PASTE LORA URL OR GDRIVE PATH HERE\"] {allow-input: true}\n",
        "\n",
        "# --- 3. ä¸‹è¼‰é‚è¼¯ ---\n",
        "def main():\n",
        "    warnings.filterwarnings('ignore', category=UserWarning, message='TypedStorage is deprecated')\n",
        "\n",
        "    available_models = {\n",
        "        \"Anything V3.1\"           : \"https://huggingface.co/cag/anything-v3-1/resolve/main/anything-v3-1.safetensors\",\n",
        "        \"AnyLoRA Default\"         : \"https://huggingface.co/Lykon/AnyLoRA/resolve/main/AnyLoRA_bakedVae_fp16_NOTpruned.safetensors\",\n",
        "        \"AnyLoRA Anime Mix\"       : \"https://huggingface.co/Lykon/AnyLoRA/resolve/main/AAM_Anylora_AnimeMix.safetensors\",\n",
        "        \"ChilloutMix Ni\"          : \"https://huggingface.co/naonovn/chilloutmix_NiPrunedFp32Fix/resolve/main/chilloutmix_NiPrunedFp32Fix.safetensors\",\n",
        "        \"Stable Diffusion V1.5\"   : \"https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.safetensors\",\n",
        "    }\n",
        "\n",
        "    REAL_MODEL_URL = available_models.get(MODEL_URL, MODEL_URL)\n",
        "\n",
        "    MODEL_URLS = REAL_MODEL_URL.split(',') if REAL_MODEL_URL and \"PASTE\" not in REAL_MODEL_URL else []\n",
        "    LORA_URLS = LORA_URL.split(',') if LORA_URL and \"PASTE\" not in LORA_URL else []\n",
        "\n",
        "    download_targets = { \"model\": (MODEL_URLS, models_dir), \"lora\": (LORA_URLS, lora_dir) }\n",
        "\n",
        "    model_path = \"\"\n",
        "    lora_path = \"\"\n",
        "\n",
        "    print_line(80, color=\"green\")\n",
        "    cprint(\" [-] Download process initiated...\", color=\"flat_yellow\")\n",
        "    print_line(80, color=\"green\")\n",
        "\n",
        "    for target, (urls, dst) in download_targets.items():\n",
        "        for url in urls:\n",
        "            if url:\n",
        "                download(url=url.strip(), dst=dst)\n",
        "                filepath = get_filepath(url, dst)\n",
        "                if os.path.exists(filepath):\n",
        "                    if target == \"model\": model_path = filepath\n",
        "                    elif target == \"lora\": lora_path = filepath\n",
        "                    file_size = py_utils.get_file_size(filepath)\n",
        "                    cprint(f\" [-] Downloaded {target.capitalize()}: {filepath} ({file_size})\", color=\"flat_yellow\")\n",
        "                else:\n",
        "                    cprint(f\" [!] Failed to find downloaded file for URL: {url}\", color=\"flat_red\")\n",
        "\n",
        "    print_line(80, color=\"green\")\n",
        "    cprint(f\"Download process has been successfully executed!\", color=\"flat_yellow\")\n",
        "    print_line(80, color=\"green\")\n",
        "\n",
        "    # å°‡çµæœå›å‚³ï¼Œè€Œä¸æ˜¯åœ¨å‡½å¼å…§å„²å­˜\n",
        "    return model_path, lora_path\n",
        "\n",
        "# --- 4. åŸ·è¡Œä¸»ç¨‹å¼ä¸¦å„²å­˜çµæœ ---\n",
        "# åŸ·è¡Œ main() ä¸¦æ¥æ”¶å®ƒå›å‚³çš„è·¯å¾‘\n",
        "model_path, lora_path = main()\n",
        "\n",
        "# åœ¨å‡½å¼å¤–éƒ¨ï¼Œä½¿ç”¨ %store å„²å­˜è®Šæ•¸\n",
        "ipython = get_ipython()\n",
        "if model_path:\n",
        "    ipython.run_line_magic('store', 'model_path')\n",
        "    cprint(f\"âœ… Model path stored: {model_path}\", color=\"flat_green\")\n",
        "if lora_path:\n",
        "    ipython.run_line_magic('store', 'lora_path')\n",
        "    cprint(f\"âœ… LoRA path stored: {lora_path}\", color=\"flat_green\")"
      ],
      "metadata": {
        "id": "BiUO8a8RwIce",
        "outputId": "c9d0c57e-5cd0-4f5e-9e7a-1b6b3e6d97b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[38;2;255;204;0m [-] Download process initiated...\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[0;32mFilename obtained: 'v1-5-pruned-emaonly.safetensors'\u001b[0m\n",
            "\u001b[0m\u001b[0;32mStarting download of 'v1-5-pruned-emaonly.safetensors' with aria2c...\u001b[0m\n",
            "\u001b[0m\u001b[0;32mDownload of 'v1-5-pruned-emaonly.safetensors' completed. Took 0 sec.\u001b[0m\n",
            "\u001b[0m\u001b[38;2;255;204;0m [-] Downloaded Model: /content/models/Stable-diffusion/v1-5-pruned-emaonly.safetensors (3.97 GB)\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[38;2;255;204;0mDownload process has been successfully executed!\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "Stored 'model_path' (str)\n",
            "\u001b[0m\u001b[38;2;0;204;102mâœ… Model path stored: /content/models/Stable-diffusion/v1-5-pruned-emaonly.safetensors\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "!wget -O /content/v1-5-pruned-emaonly.safetensors https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.safetensors\n"
      ],
      "metadata": {
        "id": "EKTLI-fs5U8Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O /content/v1-5-pruned-emaonly.safetensors https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.safetensors\n"
      ],
      "metadata": {
        "id": "NarYBchD5jhk",
        "outputId": "9447a7f3-8da1-4ce2-d91f-1feb3c0c196e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-16 15:10:27--  https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.safetensors\n",
            "Resolving huggingface.co (huggingface.co)... 108.138.246.67, 108.138.246.71, 108.138.246.79, ...\n",
            "Connecting to huggingface.co (huggingface.co)|108.138.246.67|:443... connected.\n",
            "HTTP request sent, awaiting response... 307 Temporary Redirect\n",
            "Location: /stable-diffusion-v1-5/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.safetensors [following]\n",
            "--2025-06-16 15:10:27--  https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.safetensors\n",
            "Reusing existing connection to huggingface.co:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.hf.co/repos/66/6f/666f465fa70158515404e8de2c6bc6fe2f90c46f9296293aa14daededeb32c52/6ce0161689b3853acaa03779ec93eafe75a02f4ced659bee03f50797806fa2fa?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27v1-5-pruned-emaonly.safetensors%3B+filename%3D%22v1-5-pruned-emaonly.safetensors%22%3B&Expires=1750090227&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1MDA5MDIyN319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy82Ni82Zi82NjZmNDY1ZmE3MDE1ODUxNTQwNGU4ZGUyYzZiYzZmZTJmOTBjNDZmOTI5NjI5M2FhMTRkYWVkZWRlYjMyYzUyLzZjZTAxNjE2ODliMzg1M2FjYWEwMzc3OWVjOTNlYWZlNzVhMDJmNGNlZDY1OWJlZTAzZjUwNzk3ODA2ZmEyZmE%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=hY2fya8hoeSaOELzySckW1R1kd6wy3rhd1Jm2ER%7E0zumARF6UJ-pmrpa6N0FqsXhm0hX7-mgdWFM9LuM0Wmw5fRA4K4aLoktlQOrwAfgNVO%7ED0k-ku09KXsQzE6h6gXRH1rO7d-veoAnD0F2CU3bLNKnYf5pL3StogMXYFfc%7Ewiz8gHIZhqyVjHeSA5M04ZvaCc6gIhgk%7E8GcNuquuySENZKxH9rN3zZBNPxG9IvgOutyltFubVz44GXC3SN4Zp7Vqo5QqSJJJfNBXenv7drQvsm8ZtSkPApNLF5NeBLW%7EpWG1xVp9L7t%7EXKUwuKc5Vkm1AgPV0Lu99DmqhkI8NFLQ__&Key-Pair-Id=K3RPWS32NSSJCE [following]\n",
            "--2025-06-16 15:10:27--  https://cdn-lfs.hf.co/repos/66/6f/666f465fa70158515404e8de2c6bc6fe2f90c46f9296293aa14daededeb32c52/6ce0161689b3853acaa03779ec93eafe75a02f4ced659bee03f50797806fa2fa?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27v1-5-pruned-emaonly.safetensors%3B+filename%3D%22v1-5-pruned-emaonly.safetensors%22%3B&Expires=1750090227&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1MDA5MDIyN319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy82Ni82Zi82NjZmNDY1ZmE3MDE1ODUxNTQwNGU4ZGUyYzZiYzZmZTJmOTBjNDZmOTI5NjI5M2FhMTRkYWVkZWRlYjMyYzUyLzZjZTAxNjE2ODliMzg1M2FjYWEwMzc3OWVjOTNlYWZlNzVhMDJmNGNlZDY1OWJlZTAzZjUwNzk3ODA2ZmEyZmE%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=hY2fya8hoeSaOELzySckW1R1kd6wy3rhd1Jm2ER%7E0zumARF6UJ-pmrpa6N0FqsXhm0hX7-mgdWFM9LuM0Wmw5fRA4K4aLoktlQOrwAfgNVO%7ED0k-ku09KXsQzE6h6gXRH1rO7d-veoAnD0F2CU3bLNKnYf5pL3StogMXYFfc%7Ewiz8gHIZhqyVjHeSA5M04ZvaCc6gIhgk%7E8GcNuquuySENZKxH9rN3zZBNPxG9IvgOutyltFubVz44GXC3SN4Zp7Vqo5QqSJJJfNBXenv7drQvsm8ZtSkPApNLF5NeBLW%7EpWG1xVp9L7t%7EXKUwuKc5Vkm1AgPV0Lu99DmqhkI8NFLQ__&Key-Pair-Id=K3RPWS32NSSJCE\n",
            "Resolving cdn-lfs.hf.co (cdn-lfs.hf.co)... 18.155.192.23, 18.155.192.117, 18.155.192.66, ...\n",
            "Connecting to cdn-lfs.hf.co (cdn-lfs.hf.co)|18.155.192.23|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4265146304 (4.0G) [binary/octet-stream]\n",
            "Saving to: â€˜/content/v1-5-pruned-emaonly.safetensorsâ€™\n",
            "\n",
            "/content/v1-5-prune 100%[===================>]   3.97G   229MB/s    in 25s     \n",
            "\n",
            "2025-06-16 15:10:52 (165 MB/s) - â€˜/content/v1-5-pruned-emaonly.safetensorsâ€™ saved [4265146304/4265146304]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pprint import pprint # å¼•å…¥ pprint è®“è¼¸å‡ºæ›´å¥½çœ‹\n",
        "\n",
        "# --- 1. æ‰€æœ‰è¨­å®šå·²æ ¹æ“šä½ çš„æˆªåœ–å’Œä¸‹è¼‰ç´€éŒ„å¡«å¯«å®Œç•¢ ---\n",
        "\n",
        "# (å·²å¡«å¯«) æ ¹æ“šä½ çš„ä¸‹è¼‰ç´€éŒ„ï¼Œé€™å°±æ˜¯æ¨¡å‹å­˜æ”¾çš„è³‡æ–™å¤¾è·¯å¾‘\n",
        "models_dir = \"/content/\"\n",
        "\n",
        "# (å·²å¡«å¯«) æ ¹æ“šä½ çš„ä¸‹è¼‰ç´€éŒ„ï¼Œé€™å°±æ˜¯æ¨¡å‹çš„å®Œæ•´æª”æ¡ˆåç¨±\n",
        "selected_model = \"v1-5-pruned-emaonly.safetensors\"\n",
        "\n",
        "# (ä¾†è‡ªä½ ä¹‹å‰çš„æˆªåœ–) å°ˆæ¡ˆ/ç³»åˆ—åç¨±\n",
        "project_name = \"JinnLo\"\n",
        "\n",
        "# (ä¾†è‡ªä½ ä¹‹å‰çš„æˆªåœ–) å‹•ç•«æ¨¡çµ„\n",
        "motion_module = \"SD15\"\n",
        "\n",
        "# (ä¾†è‡ªä½ ä¹‹å‰çš„æˆªåœ–) LoRA è¨­å®š\n",
        "lora_weight = 1\n",
        "lora_alpha = 1\n",
        "\n",
        "# (ä¾†è‡ªä½ ä¹‹å‰çš„æˆªåœ–) æ­£å‘æç¤ºè© (prompt)\n",
        "prompt = \"masterpiece, best quality, 1girl, solo, looking at viewer, hands on hips, (short bob:1.2), (purple hair with blue tips:1.3), blue gradient hair, (purple hair:1.2)\"\n",
        "\n",
        "# (ä¾†è‡ªä½ ä¹‹å‰çš„æˆªåœ–) åå‘æç¤ºè© (negative_prompt)\n",
        "negative_prompt = \"lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality\"\n",
        "\n",
        "\n",
        "# --- 2. ç¨‹å¼ç¢¼æœƒè‡ªå‹•è™•ç†è·¯å¾‘ (é€™éƒ¨åˆ†ä¸éœ€ä¿®æ”¹) ---\n",
        "\n",
        "print(\"æ­£åœ¨è¨­å®šè·¯å¾‘...\")\n",
        "if \"selected_model\" in globals() and selected_model:\n",
        "    model_path = os.path.join(models_dir, selected_model)\n",
        "    print(f\"âœ… åŸºç¤æ¨¡å‹è·¯å¾‘è¨­å®šæˆåŠŸ: {model_path}\")\n",
        "else:\n",
        "    model_path = \"\"\n",
        "    print(\"âŒ è­¦å‘Šï¼šæ‰¾ä¸åˆ° 'selected_model' è®Šæ•¸æˆ–è©²è®Šæ•¸ç‚ºç©ºã€‚\")\n",
        "\n",
        "\n",
        "# --- 3. æ•´åˆæ‰€æœ‰è¨­å®šåˆ°ä¸€å€‹å­—å…¸ä¸­ ---\n",
        "\n",
        "generation_config = {\n",
        "    \"project_name\": project_name,\n",
        "    \"model_config\": {\n",
        "        \"base_model_path\": model_path,\n",
        "        \"motion_module\": motion_module,\n",
        "    },\n",
        "    \"lora_config\": {\n",
        "        \"lora_weight\": lora_weight,\n",
        "        \"lora_alpha\": lora_alpha,\n",
        "    },\n",
        "    \"prompt_config\": {\n",
        "        \"prompt\": prompt,\n",
        "        \"negative_prompt\": negative_prompt,\n",
        "    },\n",
        "    \"steps\": 25,\n",
        "    \"guidance_scale\": 7.5,\n",
        "}\n",
        "\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(\"ğŸ‰ æ‰€æœ‰è¨­å®šå·²æº–å‚™å°±ç·’ï¼æœ€çµ‚è¨­å®šå¦‚ä¸‹ï¼š\")\n",
        "print(\"=\"*40)\n",
        "pprint(generation_config)"
      ],
      "metadata": {
        "id": "E4br-LlcMa3F",
        "outputId": "bec8bcf7-437a-4dc7-fcd5-d3536857daf3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "æ­£åœ¨è¨­å®šè·¯å¾‘...\n",
            "âœ… åŸºç¤æ¨¡å‹è·¯å¾‘è¨­å®šæˆåŠŸ: /content/v1-5-pruned-emaonly.safetensors\n",
            "\n",
            "========================================\n",
            "ğŸ‰ æ‰€æœ‰è¨­å®šå·²æº–å‚™å°±ç·’ï¼æœ€çµ‚è¨­å®šå¦‚ä¸‹ï¼š\n",
            "========================================\n",
            "{'guidance_scale': 7.5,\n",
            " 'lora_config': {'lora_alpha': 1, 'lora_weight': 1},\n",
            " 'model_config': {'base_model_path': '/content/v1-5-pruned-emaonly.safetensors',\n",
            "                  'motion_module': 'SD15'},\n",
            " 'project_name': 'JinnLo',\n",
            " 'prompt_config': {'negative_prompt': 'lowres, bad anatomy, bad hands, text, '\n",
            "                                      'error, missing fingers, extra digit, '\n",
            "                                      'fewer digits, cropped, worst quality, '\n",
            "                                      'low quality, normal quality',\n",
            "                   'prompt': 'masterpiece, best quality, 1girl, solo, looking '\n",
            "                             'at viewer, hands on hips, (short bob:1.2), '\n",
            "                             '(purple hair with blue tips:1.3), blue gradient '\n",
            "                             'hair, (purple hair:1.2)'},\n",
            " 'steps': 25}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## **4. Run to update list. Then select LoRA**\n",
        "import ipywidgets as widgets\n",
        "\n",
        "lora_list = os.listdir(lora_dir)\n",
        "lora_list.append(\"\")\n",
        "selected_lora = widgets.Dropdown(options=lora_list)\n",
        "\n",
        "selected_lora"
      ],
      "metadata": {
        "cellView": "form",
        "id": "UBrPEzQPMcrj",
        "outputId": "8881267e-3490-454b-cc7b-e391693c8808",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "9d5f613979c4455da314e5c3b02abeaf",
            "3ed731a3ff184bc690c38569e17cf54e",
            "1176d3de89db4c92988ca96019cfd377"
          ]
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dropdown(options=('',), value='')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9d5f613979c4455da314e5c3b02abeaf"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## **5. Inference**\n",
        "import yaml\n",
        "import os\n",
        "from colablib.utils.git_utils import validate_repo\n",
        "from colablib.colored_print import cprint, print_line\n",
        "from IPython.display import display, HTML # å¼•å…¥ display å’Œ HTML\n",
        "\n",
        "# @markdown Specify `project_name` for `config.yaml` header\n",
        "project_name     = \"JinnLo\" # @param {type: \"string\"}\n",
        "# @markdown ### **Model config**\n",
        "# é€™ä¸€æ®µçš„ .value è™•ç†æ˜¯æ­£ç¢ºçš„ï¼Œæˆ‘å€‘ä¿æŒåŸæ¨£\n",
        "if \"selected_model\" in globals():\n",
        "    model_path       = os.path.join(models_dir, selected_model)\n",
        "lora_path        = \"\"\n",
        "if \"selected_lora\" in globals() and selected_lora:\n",
        "    lora_path        = os.path.join(lora_dir, selected_lora.value)\n",
        "motion_module    = \"SD15\" # @param [\"ALL\",\"SD14\", \"SD15\"]\n",
        "#@markdown ### **LoRA Config**\n",
        "lora_weight      = 1 # @param {type: \"number\"}\n",
        "lora_alpha       = 1 # @param {type: \"number\"}\n",
        "# @markdown ### **Prompt Config**\n",
        "prompt           = \"masterpiece, best quality, 1girl, solo, looking at viewer, hands on hips, (short bob:1.2), (purple hair with blue tips:1.3), blue gradient hair, (purple eyes:1.2), (serious expression:1.1), slight frown, (cropped jacket:1.2), (purple and blue jacket:1.2), black crop top, black pleated skirt, black choker, black belt, (futuristic hair ornaments:1.1), hair clips, (subtle breast bouncing:1.3), (gentle chest movement:1.2), (slight jiggle:1.1), dynamic pose, motion, animation,\" # @param {type: \"string\"}\n",
        "negative_prompt  = \"lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, static, stiff, no movement, unnatural motion,\" # @param {type: \"string\"}\n",
        "image_path       = \"\"  # @param {type: \"string\"}\n",
        "# @markdown ### **Generation Parameter**\n",
        "steps            = 28  # @param {type: \"number\"}\n",
        "guidance_scale   = 12 # @param {type: \"number\"}\n",
        "seed             = -1 # @param {type: \"number\"}\n",
        "resolution       = \"512,512\" # @param {type: \"string\"}\n",
        "# @markdown ### **Video Duration**\n",
        "video_length     = 16 # @param {type: \"number\"}\n",
        "context_length   = 16 # @param {type: \"number\"}\n",
        "context_overlap  = -1 # @param {type: \"number\"}\n",
        "context_stride   = 0 # @param {type: \"number\"}\n",
        "# @markdown ### **Preview Settings**\n",
        "show_results     = True #@param {type:\"boolean\"}\n",
        "How_many_previous_results_to_show = 1 #@param {type:\"number\"}\n",
        "\n",
        "# --- é€™éƒ¨åˆ†çš„ç¨‹å¼ç¢¼æ˜¯æº–å‚™è¨­å®šæª”ï¼Œæˆ‘å€‘ä¿æŒåŸæ¨£ ---\n",
        "pretrained_model_path = os.path.join(diffusers_dir, DIFFUSERS_MODEL)\n",
        "inference_config_file = os.path.join(repo_dir, \"configs\", \"inference\", \"inference.yaml\")\n",
        "config_file           = os.path.join(config_dir, project_name + \".yaml\")\n",
        "\n",
        "separators = [\"*\", \"x\", \",\"]\n",
        "for separator in separators:\n",
        "    if separator in resolution:\n",
        "        width, height = [value.strip() for value in resolution.split(separator)]\n",
        "        break\n",
        "\n",
        "animate_config = { \"pretrained_model_path\": pretrained_model_path, \"inference_config\": inference_config_file, \"config\": config_file, \"L\": video_length, \"W\": width, \"H\": height, }\n",
        "image_config = { project_name : { \"base\": \"\", \"path\": model_path, \"additional_networks\": [], \"motion_module\": [], \"steps\": steps, \"guidance_scale\": guidance_scale, \"prompt\": [], \"n_prompt\": [] } }\n",
        "if lora_path.endswith(\".safetensors\"):\n",
        "    image_config[project_name][\"additional_networks\"].append(f\"{lora_path} : {lora_weight}\")\n",
        "    image_config[project_name][\"lora_alpha\"] = lora_alpha\n",
        "if motion_module == \"SD14\": image_config[project_name][\"motion_module\"].append(f\"{motion_dir}/mm_sd_v14.ckpt\")\n",
        "elif motion_module == \"SD15\": image_config[project_name][\"motion_module\"].append(f\"{motion_dir}/mm_sd_v15.ckpt\")\n",
        "else:\n",
        "    image_config[project_name][\"motion_module\"].append(f\"{motion_dir}/mm_sd_v14.ckpt\")\n",
        "    image_config[project_name][\"motion_module\"].append(f\"{motion_dir}/mm_sd_v15.ckpt\")\n",
        "if image_path: image_config[project_name][\"init_image\"] = image_path\n",
        "if seed > 0 : image_config[project_name][\"seed\"] = seed\n",
        "if prompt: image_config[project_name][\"prompt\"].append(prompt)\n",
        "if negative_prompt: image_config[project_name][\"n_prompt\"].append(negative_prompt)\n",
        "if context_length: animate_config[\"context_length\"] = context_length\n",
        "if context_overlap: animate_config[\"context_overlap\"] = context_overlap\n",
        "if context_stride: animate_config[\"context_stride\"] = context_stride\n",
        "\n",
        "def repo_check(repo_dir, animate_config, image_config):\n",
        "    repo_name, _, _ = validate_repo(repo_dir)\n",
        "    # ... (repo_check å‡½å¼å…§å®¹ä¿æŒä¸è®Š) ...\n",
        "    return animate_config, image_config\n",
        "\n",
        "def parse_args(config):\n",
        "    args = \"\"\n",
        "    # ... (parse_args å‡½å¼å…§å®¹ä¿æŒä¸è®Š) ...\n",
        "    return args.strip()\n",
        "\n",
        "def write_to_yaml(data, filename):\n",
        "    with open(filename, 'w') as file:\n",
        "        yaml.dump(data, file)\n",
        "\n",
        "# --- é€™éƒ¨åˆ†çš„ç¨‹å¼ç¢¼æ˜¯åŸ·è¡Œç”Ÿæˆï¼Œæˆ‘å€‘ä¿æŒåŸæ¨£ ---\n",
        "print_line(80, color=\"green\")\n",
        "cprint(\" [-] Initiating AnimateDiff...\", color=\"flat_yellow\")\n",
        "print_line(80, color=\"green\")\n",
        "if \"selected_model\" in globals(): cprint(f' Model: {selected_model}', color=\"flat_yellow\")\n",
        "if \"selected_lora\" in globals() and selected_lora: cprint(f' LoRA: {selected_lora.value}', color=\"flat_yellow\")\n",
        "print_line(80, color=\"green\")\n",
        "animate_config, image_config = repo_check(repo_dir, animate_config, image_config)\n",
        "animate_args = parse_args(animate_config)\n",
        "write_to_yaml(image_config, config_file)\n",
        "final_args = f\"python -m scripts.animate {animate_args}\"\n",
        "os.chdir(repo_dir)\n",
        "!{final_args}\n",
        "\n",
        "# --- é—œéµä¿®æ”¹é» ---\n",
        "# åœ¨é¡¯ç¤ºçµæœä¹‹å‰ï¼Œæ˜ç¢ºå®šç¾©æˆæœè³‡æ–™å¤¾çš„è·¯å¾‘\n",
        "# é€™æ¨£ display_results å‡½å¼æ‰çŸ¥é“è¦å»å“ªè£¡æ‰¾æª”æ¡ˆ\n",
        "if show_results:\n",
        "    cprint(f\"[*] Searching for results in project folder '{project_name}'...\", color=\"flat_blue\")\n",
        "    samples_dir = f\"samples/{project_name}\"\n",
        "\n",
        "    # é€™æ˜¯é¡¯ç¤ºçµæœçš„å‡½å¼ï¼Œæˆ‘å€‘æŠŠå®ƒä¹Ÿæ”¾åœ¨é€™è£¡ï¼Œè®“å„²å­˜æ ¼å¯ä»¥ç¨ç«‹é‹ä½œ\n",
        "    def display_results(output_dir, count=1):\n",
        "        if os.path.exists(output_dir):\n",
        "            files = [f for f in os.listdir(output_dir) if f.endswith(('.gif', '.mp4', '.png'))]\n",
        "            files.sort(key=lambda f: os.path.getmtime(os.path.join(output_dir, f)), reverse=True)\n",
        "\n",
        "            if files:\n",
        "                cprint(f\"âœ… Found {len(files)} result(s). Displaying the latest {count}.\", color=\"flat_green\")\n",
        "                display_count = min(len(files), count)\n",
        "                for i in range(display_count):\n",
        "                    file_path = os.path.join(output_dir, files[i])\n",
        "                    display(HTML(f'<h4>{files[i]}</h4><video src=\"{file_path}\" controls autoplay loop style=\"width:100%; max-width:512px;\"></video>'))\n",
        "            else:\n",
        "                cprint(f\"âš ï¸ No results found in the directory: {output_dir}\", color=\"flat_yellow\")\n",
        "        else:\n",
        "            cprint(f\"âŒ Error: The output directory does not exist: {output_dir}\", color=\"flat_red\")\n",
        "\n",
        "    display_results(samples_dir, How_many_previous_results_to_show)"
      ],
      "metadata": {
        "id": "vd1bhfbn8Q-a",
        "outputId": "6444fb3c-1020-4080-f54c-2ec5ede436f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[38;2;255;204;0m [-] Initiating AnimateDiff...\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[38;2;255;204;0m Model: v1-5-pruned-emaonly.safetensors\u001b[0m\n",
            "\u001b[0m\u001b[38;2;255;204;0m LoRA: \u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/content/AnimateDiff/scripts/animate.py\", line 9, in <module>\n",
            "    import diffusers\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/diffusers/__init__.py\", line 27, in <module>\n",
            "    from .modeling_utils import ModelMixin\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/diffusers/modeling_utils.py\", line 52, in <module>\n",
            "    import accelerate\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/__init__.py\", line 16, in <module>\n",
            "    from .accelerator import Accelerator\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/accelerator.py\", line 34, in <module>\n",
            "    from huggingface_hub import split_torch_state_dict_into_shards\n",
            "ImportError: cannot import name 'split_torch_state_dict_into_shards' from 'huggingface_hub' (/usr/local/lib/python3.11/dist-packages/huggingface_hub/__init__.py)\n",
            "\u001b[0m\u001b[38;2;0;102;204m[*] Searching for results in project folder 'JinnLo'...\u001b[0m\n",
            "\u001b[0m\u001b[38;2;204;102;102mâŒ Error: The output directory does not exist: samples/JinnLo\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## **6. Display your result**\n",
        "How_many_previous_results_to_show = 4 #@param {type:\"integer\"}\n",
        "\n",
        "display_results(How_many_previous_results_to_show)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "zHXDQOYdpkiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## **(Optional) Convert to MP4**\n",
        "from moviepy.editor import *\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "gif_path = \"/content/AnimateDiff/samples/Anime-2023-07-16T03-40-19/sample/0-(Overhead-view),dynamic-angle,ultra-detailed,-illustration,-close-up,-straight-on,-1girl,-(fantasy:1.4),-((purple.gif\" #@param {type:'string'}\n",
        "mp4_output = \"/content/output.mp4\" #@param {type:'string'}\n",
        "\n",
        "gif = VideoFileClip(gif_path)\n",
        "gif.write_videofile(mp4_output, codec='libx264')\n",
        "\n",
        "mp4 = open(mp4_output,'rb').read()\n",
        "\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "\n",
        "HTML(\"\"\"\n",
        "<video width=400 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "HOH5iABAHB0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## **(Optional) Download Generated Animation**\n",
        "# @markdown Download file manually from files tab or save to Google Drive\n",
        "import os\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth, drive\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from colablib.colored_print import cprint, print_line\n",
        "\n",
        "%store -r\n",
        "\n",
        "os.chdir(os.path.join(repo_dir, \"samples\"))\n",
        "\n",
        "use_drive = True  # @param {type:\"boolean\"}\n",
        "folder_name = \"AnimateDiff\"  # @param {type: \"string\"}\n",
        "filename = \"waifu.zip\"  # @param {type: \"string\"}\n",
        "save_as = filename\n",
        "\n",
        "name_file = os.path.splitext(filename)[0]\n",
        "if os.path.exists(filename):\n",
        "    i = 1\n",
        "    while os.path.exists(f\"{name_file}({i}).zip\"):\n",
        "        i += 1\n",
        "    filename = f\"{name_file}({i}).zip\"\n",
        "\n",
        "os.system('zip -r /content/outputs.zip .')\n",
        "\n",
        "if use_drive:\n",
        "    auth.authenticate_user()\n",
        "    gauth = GoogleAuth()\n",
        "    gauth.credentials = GoogleCredentials.get_application_default()\n",
        "    drive = GoogleDrive(gauth)\n",
        "\n",
        "    def create_folder(folder_name):\n",
        "        file_list = drive.ListFile({\n",
        "            \"q\": f\"title='{folder_name}' and mimeType='application/vnd.google-apps.folder' and trashed=false\"\n",
        "        }).GetList()\n",
        "        if file_list:\n",
        "            cprint(\"Debug: Folder exists\", color=\"green\")\n",
        "            folder_id = file_list[0][\"id\"]\n",
        "        else:\n",
        "            cprint(\"Debug: Creating folder\", color=\"green\")\n",
        "            file = drive.CreateFile({\n",
        "                \"title\": folder_name,\n",
        "                \"mimeType\": \"application/vnd.google-apps.folder\"\n",
        "            })\n",
        "            file.Upload()\n",
        "            folder_id = file.attr[\"metadata\"][\"id\"]\n",
        "        return folder_id\n",
        "\n",
        "    def upload_file(file_name, folder_id, save_as):\n",
        "        file_list = drive.ListFile({\"q\": f\"title='{save_as}' and trashed=false\"}).GetList()\n",
        "        if file_list:\n",
        "            cprint(\"Debug: File already exists\", color=\"green\")\n",
        "            i = 1\n",
        "            while True:\n",
        "                new_name = f\"{os.path.splitext(save_as)[0]}({i}){os.path.splitext(save_as)[1]}\"\n",
        "                file_list = drive.ListFile({\"q\": f\"title='{new_name}' and trashed=false\"}).GetList()\n",
        "                if not file_list:\n",
        "                    save_as = new_name\n",
        "                    break\n",
        "                i += 1\n",
        "        file = drive.CreateFile({\"title\": save_as, \"parents\": [{\"id\": folder_id}]})\n",
        "        file.SetContentFile(file_name)\n",
        "        file.Upload()\n",
        "        file.InsertPermission({\"type\": \"anyone\", \"value\": \"anyone\", \"role\": \"reader\"})\n",
        "        return file.attr[\"metadata\"][\"id\"]\n",
        "\n",
        "    file_id = upload_file(\"/content/outputs.zip\", create_folder(folder_name), save_as)\n",
        "    cprint(f\"Your sharing link: https://drive.google.com/file/d/{file_id}/view?usp=sharing\", color=\"green\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "J7fQkkLUJWTw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}